{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"DS 3001 Foundations of Machine Learning Final Project\"\n",
        "author: \"Sammy Park (scp9cqg) and Victoria Ok (vyo7tv)\"\n",
        "date: \"12/04/2023\"\n",
        "format: \n",
        "  html:\n",
        "    toc: true\n",
        "    toc-title: \"Table of Contents\"\n",
        "    toc-depth: 5\n",
        "    smooth-scroll: true\n",
        "    toc-location: left\n",
        "    theme: \"Minty\"\n",
        "editor: visual\n",
        "juypter: python3\n",
        "---"
      ],
      "id": "a9b291ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Goal\n",
        "To develop a predictive model for song popularity, aiming to assess and compare the popularity of a user's top 10 songs based on their musical features in relation to the top tracks.\n",
        "\n",
        "## Question\n",
        "Can we predict the popularity of songs based on their musical features?\n",
        "\n",
        "(duration, explicitness, danceability, energy, key, loudness, modality of the track, speech presence, acousticness, instrumentalness, liveness, valence, tempo, and time signature)\n",
        "\n",
        "# Data\n",
        "\n",
        "## Spotify Tracks Dataset from huggingface.co\n",
        "[https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset)\n",
        "\n",
        "## Data Description:\n",
        "The dataset comprises information on various music tracks available on Spotify, encompassing diverse attributes such as artist details, album names, track names, popularity scores, duration, explicit content, and musical traits like danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time signature, and track genre. The popularity score, ranging from 0 to 100, is algorithmically determined based on the track's play count and recency. Additionally, the dataset includes details about the presence of explicit lyrics, dance suitability, acoustic nature, instrumental content, live performance likelihood, and the emotional tone conveyed by each track. \n",
        "\n",
        "## Basic Information about the Data:\n",
        "- size: 17.5+ MB\n",
        "- number of entries (rows): 114,000\n",
        "- number of features (columns): 21\n",
        "- number of categorical columns: 6\n",
        "- number of numerical columns: 15\n",
        "- columns with missing values: `artists`, `album_name`, `track_name`\n",
        "\n",
        "### Key Variables (from data documentation):\n",
        "- `track_genre`: The genre in which the track belongs\n",
        "- `popularity`: The popularity of a track is a value between 0 and 100, with 100 being the most popular, calculated algorithmically based on the total plays and recency of a track. Current plays contribute more to higher popularity. Duplicate tracks are independently rated, and artist/album popularity is derived from track popularity.\n",
        "- `duration_ms`: The track length in milliseconds\n",
        "- `explicit`: Whether or not the track has explicit lyrics (true = yes it does; false = no it does not OR unknown)\n",
        "- `danceability`: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\n",
        "- `energy`: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy.\n",
        "- `key`: The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1\n",
        "- `loudness`: The overall loudness of a track in decibels (dB)\n",
        "- `mode`: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0\n",
        "- `speechiness`: Speechiness measures the presence of spoken words in a track. A value close to 1.0 indicates exclusively spoken content, with values above 0.66 suggesting entirely spoken tracks. Values between 0.33 and 0.66 indicate a mix of music and speech, such as rap, while values below 0.33 likely represent non-speech-like music tracks.\n",
        "- `acousticness`: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic\n",
        "- `instrumentalness`: Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content\n",
        "- `liveness`: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live\n",
        "- `valence`: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)\n",
        "- `tempo`: The overall estimated tempo of a track in beats per minute (BPM).\n",
        "- `time_signature`: An estimated time signature. The time signature ranges from 3 to 7 indicating time signatures of 3/4, to 7/4.\n",
        "\n",
        "# Data Preprocessing\n",
        "## Loading Libraries and Data"
      ],
      "id": "668f2613"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Import necessary packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lime import lime_tabular\n",
        "\n",
        "# libraries for data pre-processing\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Libraries for kMeans clustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Libraries for random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Libraries for model evaluation and metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "id": "a622b8c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Load and preview the dataset\n",
        "# spotify = pd.read_csv(\"/Users/SammyCPark/Desktop/DS3001/DS-3001/spotify_dataset.csv\") # Sammy path\n",
        "spotify = pd.read_csv(\"C:/Users/victo/Downloads/Yr. 4 Sem. 1/DS 3001 FML/ds3001-final-project/dataset.csv\") # Victoria path\n",
        "spotify.info()"
      ],
      "id": "f7d4bc0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ],
      "id": "bde3d14f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Drop the index column, as it is an unnecessary column\n",
        "# Drop the track_id column, because it is a unique identifier \n",
        "spotify = spotify.drop(['index', 'track_id'], axis=1)\n",
        "spotify.info()"
      ],
      "id": "68e7246c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert 'duration_ms' into 'duration_sec' (ms to s) for user readability\n",
        "spotify['duration_sec'] = spotify['duration_ms']/1000\n",
        "spotify = spotify.drop(['duration_ms'], axis=1)\n",
        "spotify.info()"
      ],
      "id": "c28f86ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# See how many categories exist in track_genre (114)\n",
        "genres = spotify[\"track_genre\"].value_counts()\n",
        "genres"
      ],
      "id": "46de8c2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compress track_genre into smaller categories\n",
        "def categorize_genre(genre):\n",
        "    if genre in [\"hip-hop\", \"power-pop\", \"pop-film\", \"pop\", \"mandopop\", \"k-pop\", \"j-pop\", \"j-idol\", \"cantopop\"]:\n",
        "        return \"Pop_HipHop\"\n",
        "    elif genre in [\"electronic\", \"electro\", \"edm\", \"dub\", \"dubstep\", \"groove\", \"idm\", \"breakbeat\", \"minimal-techno\", \"techno\", \"synth-pop\", \"detroit-techno\", \"party\", \"club\"]:\n",
        "        return \"Electronic\"\n",
        "    elif genre in [\"progressive-house\", \"afrobeat\", \"house\", \"chicago-house\", \"drum-and-bass\", \"tango\", \"reggaeton\", \"reggae\", \"disco\", \"deep-house\", \"dancehall\", \"dance\", \"funk\", \"garage\", \"samba\", \"salsa\", \"trance\"]:\n",
        "        return \"Dance\"\n",
        "    elif genre in [\"mpb\", \"malay\", \"latino\", \"latin\", \"j-rock\", \"j-dance\", \"world-music\", \"german\", \"french\", \"british\", \"brazil\", \"iranian\", \"turkish\", \"anime\", \"forro\", \"sertanejo\", \"indian\", \"swedish\", \"spanish\", \"trip-hop\", \"pagode\", \"ska\"]:\n",
        "        return \"World\"\n",
        "    elif genre in [\"songwriter\", \"singer-songwriter\", \"indie-pop\", \"indie\", \"bluegrass\", \"folk\", \"country\", \"honky-tonk\", \"alternative\"]:\n",
        "        return \"Indie_Country\"\n",
        "    elif genre in [\"punk\", \"metalcore\", \"metal\", \"psych-rock\", \"punk-rock\", \"heavy-metal\", \"hardstyle\", \"hardcore\", \"hard-rock\", \"black-metal\", \"alt-rock\", \"rockabilly\", \"rock-n-roll\", \"rock\", \"death-metal\", \"grunge\", \"grindcore\", \"goth\", \"emo\", \"industrial\"]:\n",
        "        return \"Metal_Rock\"\n",
        "    elif genre in [\"acoustic\", \"piano\", \"jazz\", \"blues\", \"r-n-b\", \"ambient\", \"soul\", \"guitar\", \"gospel\", \"opera\", \"classical\"]:\n",
        "        return \"Blues_Instrumental\"\n",
        "    elif genre in [\"kids\", \"study\", \"sleep\", \"show-tunes\", \"disney\", \"comedy\", \"children\", \"sad\", \"romance\", \"happy\", \"chill\", \"new-age\"]:\n",
        "        return \"Tunes\""
      ],
      "id": "264adebb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply the categorization function to the 'track_genre' column\n",
        "spotify['track_genre'] = spotify['track_genre'].apply(categorize_genre).astype(\"category\")"
      ],
      "id": "a9427436",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spotify.info()"
      ],
      "id": "6a1be39d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# One hot encoding track_genre \n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "spotify[['track_genre']] = ordinal_encoder.fit_transform(spotify[['track_genre']])\n",
        "spotify[['track_genre']].value_counts()"
      ],
      "id": "211469eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# View the encoded categories of track_genre\n",
        "ordinal_encoder.categories_"
      ],
      "id": "63d5e325",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# view the null rows\n",
        "spotify[spotify.isna().any(axis=1)]"
      ],
      "id": "55fa7c6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Drop the one value that has null values\n",
        "spotify = spotify.dropna()\n",
        "spotify.info()"
      ],
      "id": "413f637f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis\n",
        "::: {.panel-tabset}\n",
        "\n",
        "## Numerical Data Summary"
      ],
      "id": "312bcedc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Output basic statistics from the numerical features\n",
        "spotify.describe()"
      ],
      "id": "dbcdf9b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Histogram"
      ],
      "id": "3de55329"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize numerical data as histograms to understand general distributions\n",
        "spotify.hist(bins=50, figsize=(20,15))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "57add622",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlations\n",
        "On the first 10,000 samples in the dataset."
      ],
      "id": "274ae074"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spotify_num_corr = spotify.drop(columns=['artists','album_name','track_name'], axis=1)[0:10000]"
      ],
      "id": "91892a10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "correlations = spotify_num_corr.corr()\n",
        "correlations.shape"
      ],
      "id": "98d39c1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "correlations[\"popularity\"].sort_values(ascending=False)"
      ],
      "id": "d3ecad13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# plot the correlations for the highest correlations\n",
        "attributes = [\"popularity\", \"loudness\", \"valence\", \"energy\"]\n",
        "scatter_matrix(spotify_num_corr[attributes], figsize=(12, 8))"
      ],
      "id": "7974cbc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Viewing the histogram, we saw that many songs had a popularity of 0, and wanted to investigate"
      ],
      "id": "3d36cccf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "zero_pop = spotify[(spotify['popularity']==0)]\n",
        "zero_pop"
      ],
      "id": "dd28a3be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There doesn't seem to be any glaring patterns (ex. track's audio features all being 0), so we will leave these be.\n",
        "\n",
        "Viewing the statistics of our target variable, we want to categorize the popularity variable into 3 classes: low, average, and high popularity. To make each class balanced (to prevent misleading accuracy scores). \n"
      ],
      "id": "3aeb38f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"33rd: \", np.percentile(spotify['popularity'], 33))\n",
        "print(\"67rd: \", np.percentile(spotify['popularity'], 67))"
      ],
      "id": "d0b3ba69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will split the data as:\n",
        "\n",
        "- Low: 0 - 33\n",
        "- Average: 33 - 67\n",
        "- High: 67 - 100\n"
      ],
      "id": "9ac13730"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Factor popularity to 3 levels of low, average, and high to create our classifier variable\n",
        "spotify['popularity'] = spotify.popularity.apply(lambda x: \"low\" if x <= 22\n",
        "                                                         else (\"average\" if (x > 22 and x <=45)\n",
        "                                                         else \"high\")).astype(\"category\")\n",
        "spotify.info()"
      ],
      "id": "c7f58709",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Duplicates, based on the documentation are the same tracks, but either from a single or an album. We have decided to drop any duplicates because the only difference between the two samples would essentially be the album name. \n"
      ],
      "id": "d737fccd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# identify the rows that are duplicated\n",
        "duplicated = spotify.duplicated()\n",
        "duplicate_indices = duplicated.index[duplicated == True].tolist()\n",
        "len(duplicate_indices)"
      ],
      "id": "21514533",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# drop the duplicated samples\n",
        "spotify = spotify.drop(duplicate_indices)\n",
        "spotify.info()"
      ],
      "id": "5a8c919b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check that all duplicates were removed\n",
        "spotify.duplicated().index[spotify.duplicated() == True].tolist()"
      ],
      "id": "6c010096",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have 101,318 samples in our dataset\n"
      ],
      "id": "bf1128c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check how many samples are in each population category\n",
        "spotify[['popularity']].value_counts()"
      ],
      "id": "4b40a4a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# One hot encoding popularity for classification\n",
        "spotify[['popularity']] = OrdinalEncoder().fit_transform(spotify[['popularity']])\n",
        "spotify[['popularity']].value_counts()"
      ],
      "id": "cb496ac0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 0 corresponds with average popularity\n",
        "- 1 corresponds with high popularity\n",
        "- 2 corresponds with low popularity\n",
        "\n",
        "## kMeans Clustering\n",
        "Employ kMeans clustering as a data exploration technique to uncover underlying patterns and structures within the dataset, allowing for the identification of general trends, associations, or distinctive patterns in the data.\n"
      ],
      "id": "ae508412"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Subset data without the artist, album name, and track name to create numerical dataset\n",
        "spotify_num = spotify.drop(columns=['artists','album_name','track_name'], axis=1)\n",
        "spotify_num.info()"
      ],
      "id": "1ef0b496",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scale the data for kmeans\n",
        "spotify_scaled_kmeans = pd.DataFrame(MinMaxScaler().fit_transform(spotify_num))"
      ],
      "id": "3a365e21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run data through kmeans model for 3 clusters\n",
        "spotify_kmeans = KMeans(n_clusters=3, random_state=42, n_init=10).fit(spotify_scaled_kmeans)"
      ],
      "id": "5f4e48a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# see what the model labeled the training dataset\n",
        "print(spotify_kmeans.labels_)\n",
        "print(spotify_kmeans.predict(spotify_scaled_kmeans))"
      ],
      "id": "f9782cd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scatterplots\n",
        "::: {.panel-tabset}\n",
        "## Energy vs. Loudness"
      ],
      "id": "90921e91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "group1 = spotify_scaled_kmeans[spotify_kmeans.labels_ == 0]\n",
        "group2= spotify_scaled_kmeans[spotify_kmeans.labels_ == 1]\n",
        "group3 = spotify_scaled_kmeans[spotify_kmeans.labels_ == 2]\n",
        "\n",
        "plt.scatter(group1[3], group1[5], c=\"orange\", s=1, alpha=0.25)\n",
        "plt.scatter(group2[3], group2[5], c=\"green\", s=1, alpha=0.25)\n",
        "plt.scatter(group3[3], group3[5], c=\"purple\", s=1, alpha=0.25)\n",
        "plt.xlabel(\"energy\")\n",
        "plt.ylabel(\"loudness\")"
      ],
      "id": "0373e274",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tempo vs. Valence"
      ],
      "id": "f4502fa3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.scatter(group1[12], group1[11], c=\"orange\", s=1, alpha=0.25)\n",
        "plt.scatter(group2[12], group2[11], c=\"green\", s=1, alpha=0.25)\n",
        "plt.scatter(group3[12], group3[11], c=\"purple\", s=1, alpha=0.25)\n",
        "plt.xlabel(\"tempo\")\n",
        "plt.ylabel(\"valence\")"
      ],
      "id": "09904f69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "# Methods\n",
        "## Random Forest\n",
        "Apply Random Forest to establish a predictive model for song popularity, enabling the assessment and comparison of a user's top 10 songs based on their musical features and their relation to top tracks.\n"
      ],
      "id": "009dc8da"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# split the data into predictors and labels\n",
        "X = spotify.drop(columns=[\"popularity\"], axis=1)\n",
        "y = spotify['popularity']"
      ],
      "id": "f1e13ccd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# split the data into training and testing sets\n",
        "# training: 80%\n",
        "# testing: 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42) "
      ],
      "id": "db71f1d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# verify that sets were stratified:\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "id": "90b054be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# drop the track artist/album information\n",
        "X_train_new = X_train.drop(columns=['artists', 'album_name', 'track_name'])\n",
        "X_test_new = X_test.drop(columns=['artists', 'album_name', 'track_name'])"
      ],
      "id": "cea9f28b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get a summary of the training dataset (+ verify that drops performed correctly)\n",
        "X_train_new.info()"
      ],
      "id": "1dd1331a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get a summary of the training dataset (+ verify that drops performed correctly)\n",
        "X_test_new.info()"
      ],
      "id": "f4fc7c0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a basic model"
      ],
      "id": "af11d23b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "RFC = RandomForestClassifier(\n",
        "        n_estimators = 1000, \n",
        "        max_features = 4, # square root of number of features\n",
        "        bootstrap = True, \n",
        "        max_samples = 10000, \n",
        "        oob_score = True, \n",
        "        random_state = 42,\n",
        "        n_jobs = -1,\n",
        "        verbose = True\n",
        ")"
      ],
      "id": "25afa2b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# fit the classifier on the training set\n",
        "spotify_RFC = RFC.fit(X_train_new, y_train)"
      ],
      "id": "2f67ba79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get the predictions of the model on the training set\n",
        "y_train_pred = spotify_RFC.predict(X_train_new)\n",
        "y_train_pred"
      ],
      "id": "3a5069ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Model Evaluation and Metrics\n"
      ],
      "id": "48bca24c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# precision\n",
        "print(\"training precision: \", metrics.precision_score(y_train, y_train_pred, average=\"weighted\"))"
      ],
      "id": "4ba28cb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# recall\n",
        "print(\"training recall: \", metrics.recall_score(y_train, y_train_pred, average='weighted'))"
      ],
      "id": "984fe5a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# accuracy\n",
        "print(\"training accuracy: \", spotify_RFC.score(X_train_new, y_train))"
      ],
      "id": "8f56dbbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# out of bag error:\n",
        "print('training OOB error rate: ' + str(1-spotify_RFC.oob_score_))"
      ],
      "id": "bf8971ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix"
      ],
      "id": "e87099c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# output the confusion matrix for a visualization\n",
        "ConfusionMatrixDisplay.from_estimator(spotify_RFC, X_train_new, y_train)"
      ],
      "id": "a4a7e908",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Summary \n",
        "\n",
        "- Precision: 0.80\n",
        "- Recall: 0.80\n",
        "- Accuracy: 0.80\n",
        "- OOB error: 0.40\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "Find the most optimal values for two hyperparameters: ```n_estimators``` and ```max_features``` to find the best model.\n",
        "\n",
        "::: {.panel-tabset}\n",
        "## n_estimators"
      ],
      "id": "13fd32dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_estimators_list = [100, 300, 500, 700, 900, 1000]\n",
        "forest_list = [RandomForestClassifier( \n",
        "                n_estimators = n,\n",
        "                max_features = 4, # square root of number of features\n",
        "                bootstrap = True, \n",
        "                warm_start=True,\n",
        "                max_samples = 10000, \n",
        "                oob_score = True, \n",
        "                random_state = 42).fit(X_train_new, y_train) for n in n_estimators_list]\n",
        "\n",
        "# Take the first three\n",
        "forest_list[:3]"
      ],
      "id": "d9bc9c4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# visualize how the error rate changes as the number of trees increases\n",
        "oob_errors = ([1-i.oob_score_ for i in forest_list])\n",
        "plt.plot(n_estimators_list,oob_errors)\n",
        "plt.title('Out Of Bag Error Against Number of Trees')\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylabel('Out of Bag Error')\n",
        "plt.show()"
      ],
      "id": "982fc375",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# view the OOB errors in a table\n",
        "pd.DataFrame(list(zip(n_estimators_list, oob_errors)), columns = ['number of trees','oob_error'])"
      ],
      "id": "18a93a15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making ```n_estimators``` = 1000 has the highest performance.\n",
        "\n",
        "## max_features"
      ],
      "id": "98746fbe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_features_list = [4, 7, 11, 15]\n",
        "\n",
        "forest_list2 = [RandomForestClassifier(\n",
        "                n_estimators = 1000, # what we found to be the most optimal\n",
        "                max_features= n, \n",
        "                bootstrap = True, \n",
        "                warm_start=True,\n",
        "                max_samples = 5000, \n",
        "                oob_score = True, \n",
        "                random_state = 42).fit(X_train_new, y_train) for n in max_features_list]\n",
        "\n",
        "forest_list2[:3]"
      ],
      "id": "8963e0a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oob_errors1 = ([1 - i.oob_score_ for i in forest_list2])\n",
        "plt.plot(max_features_list, oob_errors1)\n",
        "plt.title('Out Of Bag Error Against Number of Trees')\n",
        "plt.xlabel('max_features_list')\n",
        "plt.ylabel('Out of Bag Error')\n",
        "plt.show() "
      ],
      "id": "04c5f0f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.DataFrame(list(zip(max_features_list, oob_errors1)), columns = ['number of features','oob_error'])"
      ],
      "id": "a6fae061",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having 4 features shows to have the smallest OOB error\n",
        "\n",
        ":::\n",
        "\n",
        "Our new model will have max 1000 trees and max 4 features.\n"
      ],
      "id": "d1e92e58"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# create the new model (train on whole dataset)\n",
        "spotify_RFC_tune = RandomForestClassifier(\n",
        "                n_estimators = 1000, # what we found to be the most optimal\n",
        "                max_features= 4, # what we found to be the most optimal\n",
        "                bootstrap = True, \n",
        "                oob_score = True, \n",
        "                random_state = 42,\n",
        "                n_jobs = -1,\n",
        "                verbose = True)\n",
        "spotify_RFC_tune"
      ],
      "id": "5af38a31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# fit the data\n",
        "spotify_RF_tuned = spotify_RFC_tune.fit(X_train_new, y_train)"
      ],
      "id": "014c442a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pd.DataFrame(spotify_RF_tuned.feature_importances_,index = X_train_new.columns, columns=['importance']).sort_values('importance', ascending=False))"
      ],
      "id": "7873df91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Importance"
      ],
      "id": "fe9d88f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Here we compute both the mean and standard\n",
        "# deviation of accumulation of the impurity decrease within each tree.\n",
        "importances = spotify_RF_tuned.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in spotify_RF_tuned.estimators_], axis=0)\n",
        "\n",
        "#graph it\n",
        "forest_importances = pd.Series(importances, index=X_train_new.columns)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "fig.tight_layout()"
      ],
      "id": "9cce1eaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate the Final Model on Test Set\n"
      ],
      "id": "71e22aa0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test_pred = spotify_RF_tuned.predict(X_test_new)\n",
        "y_test_pred"
      ],
      "id": "baae0cda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# precision\n",
        "print(\"testing precision: \", metrics.precision_score(y_test, y_test_pred, average=\"weighted\"))"
      ],
      "id": "1b0155e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# recall\n",
        "print(\"testing recall: \", metrics.recall_score(y_test, y_test_pred, average='weighted'))"
      ],
      "id": "2ccce8ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# accuracy\n",
        "print(\"testing accuracy: \", spotify_RF_tuned.score(X_test_new, y_test))"
      ],
      "id": "eb38d704",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# out of bag error:\n",
        "print('testing OOB error rate: ' + str(1-spotify_RF_tuned.oob_score_))"
      ],
      "id": "f44dbd00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix"
      ],
      "id": "61c3c614"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ConfusionMatrixDisplay.from_estimator(spotify_RF_tuned, X_test_new, y_test)"
      ],
      "id": "aa84ade4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Summary\n",
        "\n",
        "- Precision: 0.64\n",
        "- Recall: 0.64\n",
        "- Accuracy: 0.64\n",
        "\n",
        "\n",
        "# Application\n",
        "Apply to our top 10 songs of 2023"
      ],
      "id": "7fea3542"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# load Sammy's top 10\n",
        "sammy_top10 = pd.read_csv(\"C:/Users/victo/Downloads/Yr. 4 Sem. 1/DS 3001 FML/ds3001-final-project/top10_sammy.csv\")\n",
        "# load Victoria's top 10\n",
        "victoria_top10 = pd.read_csv(\"C:/Users/victo/Downloads/Yr. 4 Sem. 1/DS 3001 FML/ds3001-final-project/top10_victoria.csv\")"
      ],
      "id": "8d511d8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sammy_top10.info()"
      ],
      "id": "14b61cca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "victoria_top10.info()"
      ],
      "id": "b221e410",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sammy_top10 = sammy_top10.drop(columns=[\"index\", \"artists\", \"album_name\", \"track_name\"])\n",
        "victoria_top10 = victoria_top10.drop(columns=[\"index\", \"artists\", \"album_name\", \"track_name\"])"
      ],
      "id": "b61a9610",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sammy_top10['duration_sec'] = sammy_top10['duration_ms']/1000\n",
        "sammy_top10 = sammy_top10.drop(['duration_ms'], axis=1)\n",
        "victoria_top10['duration_sec'] = victoria_top10['duration_ms']/1000\n",
        "victoria_top10 = victoria_top10.drop(['duration_ms'], axis=1)"
      ],
      "id": "b724eb79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions = ['low', 'average', 'high']"
      ],
      "id": "62a56bfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sammy_pred = spotify_RF_tuned.predict(sammy_top10)\n",
        "sammy_pred"
      ],
      "id": "c1ca824e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sammy_count =[1, 0, 9]\n",
        "plt.bar(predictions, sammy_count)\n",
        "plt.xlabel(\"Popularity Type\") \n",
        "plt.ylabel(\"Count\") \n",
        "plt.title(\"Sammy's Track Popularity Predictions\")"
      ],
      "id": "367f7b3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most of the songs that Sammy listens to are considered popular, just one is considered to have low popularity\n",
        "\n",
        "Analyze the top song:"
      ],
      "id": "61a2be5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Create an explainer object\n",
        "explainer = lime_tabular.LimeTabularExplainer(sammy_top10.values,feature_names=sammy_top10.columns,class_names=['Low','Average', 'High'],discretize_continuous=True)\n",
        "\n",
        "#Get the explanation for RF\n",
        "exp = explainer.explain_instance(sammy_top10.values[0],spotify_RF_tuned.predict_proba,num_features=15)\n",
        "#next\n",
        "#Show the explanation\n",
        "exp.show_in_notebook(show_table=True, show_all=False)"
      ],
      "id": "313929b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "victoria_pred = spotify_RF_tuned.predict(victoria_top10)\n",
        "victoria_pred"
      ],
      "id": "98e970e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "victoria_count = [0, 6, 4]\n",
        "plt.bar(predictions, victoria_count)\n",
        "plt.xlabel(\"Popularity Type\") \n",
        "plt.ylabel(\"Count\") \n",
        "plt.title(\"Victoria's Track Popularity Predictions\") "
      ],
      "id": "6042c7ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The songs that Victoria listens to are almost split evenly between average and high popularity.\n",
        "\n",
        "Analyze the top song:"
      ],
      "id": "ed1a8cdb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Create an explainer object\n",
        "explainer = lime_tabular.LimeTabularExplainer(victoria_top10.values,feature_names=victoria_top10.columns,class_names=['Low','Average', 'High'],discretize_continuous=True)\n",
        "\n",
        "#Get the explanation for RF\n",
        "exp = explainer.explain_instance(victoria_top10.values[0],spotify_RF_tuned.predict_proba,num_features=15)\n",
        "#next\n",
        "#Show the explanation\n",
        "exp.show_in_notebook(show_table=True, show_all=False)"
      ],
      "id": "ae021206",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation\n",
        "1. Precision:\n",
        "- Training Data: 80%\n",
        "- Testing Data: 64%\n",
        "Precision measures the accuracy of the positive predictions made by the model. In the context of predicting song popularity, precision would indicate the proportion of songs predicted to be popular that are actually popular. An 80% precision on the training data suggests that, of the songs predicted to be popular, 80% are indeed popular. However, there is a decrease in precision on the testing data to 64%, which means a lower proportion of predicted popular songs are actually popular in the test set.\n",
        "\n",
        "2. Recall (Sensitivity):\n",
        "- Training Data: 80%\n",
        "- Testing Data: 64%\n",
        "Recall measures the ability of the model to capture all the relevant instances (popular songs in this case). An 80% recall on the training data suggests that the model is good at identifying popular songs. However, on the testing data, the recall drops to 64%, indicating that the model might be missing some popular songs in the test set.\n",
        "\n",
        "3. Accuracy:\n",
        "- Training Data: 80%\n",
        "- Testing Data: 64%\n",
        "Accuracy measures the overall correctness of predictions. While 80% accuracy on the training data indicates that the model performs well on the training set, the drop to 64% on the testing data suggests a decrease in overall performance. This could be due to the model's inability to generalize well to new, unseen songs.\n",
        "\n",
        "4. Out-of-Bag (OOB) Error:\n",
        "- Training Data: 40%\n",
        "- Testing Data: 43%\n",
        "The OOB error is a measure used in Random Forest models. In this case, a 40% OOB error on the training data suggests that the model performs well on unseen samples during the training phase. However, the increase in OOB error to 43% on the testing data implies a potential drop in generalization performance, indicating that the model may not perform as well on new songs.\n",
        "\n",
        "# Conclusion\n",
        "In summary, the model seems to perform well on the training data, but there is a decrease in performance on the testing data, which suggests a potential issue with overfitting or lack of generalization. Further analysis and potentially adjusting the model or features may be necessary to improve its performance on new, unseen songs. Some possible actions we can take to learn underlying patterns better and reduce overfitting are:\n",
        "\n",
        "- Providing more diverse and representative training data can help the model. \n",
        "- Pruning the decision trees by removing branches that do not contribute significantly to the model's performance. This prevents the tree from becoming too deep and overfitting the training data.\n",
        "- Remove features with lower variable importance to reduce noise.\n",
        "\n",
        "# Future Work/Considerations\n",
        "While the analysis benefited from variables like duration, explicitness, danceability, and others, limitations arose due to each genre having 1000 tracks, potentially resulting in an incomplete representation. Still, the dataset let us see how songs are somewhat normally distributed in popularity. To further the analysis, exploring user-specific factors (individual preferences, demographics, listening history) and external influences (cultural trends, regional preferences) could enhance the model's accuracy in predicting song popularity for diverse user profiles.\n",
        "\n",
        "In addition, in the future, we would also consider more hyperparameter tuning. Due to slow hardware, we were unable to test a vast range of values for `n_features` and `max_features`, so there may be more optimal values. In addition, the Random Forest Classifier has many other hyperparameters, such as `max_leaf_nodes` and `max_depth`, that we could also tune to create a better model. "
      ],
      "id": "0222e2f1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}